{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2348a156",
   "metadata": {},
   "source": [
    "# Requirement 2:\n",
    "# This is Assignment 11-Casey Quinn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d0c817",
   "metadata": {},
   "source": [
    "# Requirement 3:\n",
    "\n",
    "# Commonalities:\n",
    "* Both Pandas series objects and NumPy arrays are often much more efficient than built-in Python objects such as lists or dictionaries. This is because they both have type-specific compiled code. Both Pandas series objects and NumPy arrays support array-style operations such as slicing.\n",
    "* Both support uFunc type operations where you can do element-wise operations. This means they have similar capabilities that are lacking with a regular Python list.\n",
    "# Differences:\n",
    "* A major difference between them is the index because with a NumPy array it has a fixed integer index with a step of 1 while a Pandas series object can have an explicitly defined index associated with the values. This means that the index values can be of any type. For example, the index in a series could be a string similar to a Python dictionary.\n",
    "* This gives the series additional capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e415ed0",
   "metadata": {},
   "source": [
    "# Requirement 4:\n",
    "<!-- 4. Create a Pandas series named bill_names with American currency bill\n",
    "denominations as indices (keys) and President last names as values. For\n",
    "example: 1 – Washington, 2 – Jefferson, etc. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30674227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1          George Washington\n",
       "2           Thomas Jefferson\n",
       "5            Abraham Lincoln\n",
       "10        Alexander Hamilton\n",
       "20            Andrew Jackson\n",
       "50          Ulysses S. Grant\n",
       "100        Benjamin Franklin\n",
       "500                 McKinley\n",
       "1000               Cleveland\n",
       "5000           James Madison\n",
       "10000        Salmon P. Chase\n",
       "100000        Woodrow Wilson\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "bill_names = pd.Series({1: 'George Washington', 2: 'Thomas Jefferson',\n",
    "                        5: 'Abraham Lincoln', 10: 'Alexander Hamilton',\n",
    "                        20: 'Andrew Jackson', 50: 'Ulysses S. Grant',\n",
    "                        100: 'Benjamin Franklin', 500: 'McKinley',\n",
    "                        1000: 'Cleveland', 5000: 'James Madison',\n",
    "                        10000: 'Salmon P. Chase', 100000: 'Woodrow Wilson'})\n",
    "bill_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8848a2",
   "metadata": {},
   "source": [
    "# Requirement 5:\n",
    "<!-- 5. Create a Pandas series-as-dictionary beverages_dict. Make the indices\n",
    "beverage names and comments about the beverage as values. For example:\n",
    "‘Aquafina’: ‘This is my favorite bottled water!’. Demonstrate accessing:\n",
    "• individual values via the keys\n",
    "• multiple values via slicing -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a95a9c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demonstrations:\n",
      "\n",
      "Accessing individual values via the keys:\n",
      "Mountain Dew: This is my favorite pop but it has a lot of sugar.\n",
      "\n",
      "Demonstrating accessing multiple values via slicing:\n",
      "Slice last three rows of the series:\n",
      " Whiskey                 Don't drink too much! You may get sick.\n",
      "Stoli Doli    This is a popular pineapple infused stoli mart...\n",
      "Coffee        I prefer making French presses when drinking c...\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "beverages_dict = {'Mountain Dew': 'This is my favorite pop but it has a lot of sugar.',\n",
    "                  'Gatorade': 'This is my favorite beverage when playing soccer!',\n",
    "                  'Water': 'There is no life without water...',\n",
    "                  'Whiskey': \"Don't drink too much! You may get sick.\",\n",
    "                  'Stoli Doli': 'This is a popular pineapple infused stoli martini at the restaurant I work at.',\n",
    "                  'Coffee': 'I prefer making French presses when drinking coffee. Try not to drink after 1pm.'}\n",
    "beverages_dict = pd.Series(beverages_dict)\n",
    "print('Demonstrations:\\n')\n",
    "print('Accessing individual values via the keys:')\n",
    "print('Mountain Dew:', beverages_dict['Mountain Dew'])\n",
    "print('\\nDemonstrating accessing multiple values via slicing:')\n",
    "print('Slice last three rows of the series:\\n', beverages_dict[-3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45a1af6",
   "metadata": {},
   "source": [
    "# Requirement 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e91e0439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chongquing     31020000.0\n",
       "Shanghai       27795702.0\n",
       "Tokyo          13960000.0\n",
       "Moscow         12593252.0\n",
       "Mexico City    21918936.0\n",
       "London          9425622.0\n",
       "New York       18823000.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtain real city proper population data\n",
    "city_pop_dict = {'Chongquing': 31.02e6, 'Shanghai': 27795702, 'Tokyo': 13.96e6, \n",
    "                 'Moscow': 12593252, 'Mexico City': 21918936, 'London': 9425622,\n",
    "                 'New York': 18823000}\n",
    "population = pd.Series(city_pop_dict)\n",
    "population.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41c1d04",
   "metadata": {},
   "source": [
    "# Requirement 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11a4459e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chongquing             China\n",
       "Shanghai               China\n",
       "Tokyo                  Japan\n",
       "Moscow                Russia\n",
       "Mexico City           Mexico\n",
       "London               England\n",
       "New York       United States\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -Create a Pandas series-as-dict named city_country with the cities in population and the countries \n",
    "# for each city\n",
    "city_country_dict = {'Chongquing': 'China',\n",
    "                     'Shanghai': 'China', \n",
    "                     'Tokyo': 'Japan',\n",
    "                     'Moscow': 'Russia',\n",
    "                     'Mexico City': 'Mexico',\n",
    "                     'London': 'England',\n",
    "                     'New York': 'United States'}\n",
    "city_country = pd.Series(city_country_dict)\n",
    "city_country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be15cf7e",
   "metadata": {},
   "source": [
    "# Requirement 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c0a4f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "              population   city_country\n",
      "Chongquing   31020000.0          China\n",
      "Shanghai     27795702.0          China\n",
      "Tokyo        13960000.0          Japan\n",
      "Moscow       12593252.0         Russia\n",
      "Mexico City  21918936.0         Mexico\n",
      "London        9425622.0        England\n",
      "New York     18823000.0  United States \n",
      "\n",
      "Showing .index property:\n",
      "Index(['Chongquing', 'Shanghai', 'Tokyo', 'Moscow', 'Mexico City', 'London',\n",
      "       'New York'],\n",
      "      dtype='object')\n",
      "\n",
      "Showing .columns property:\n",
      "Index(['population', 'city_country'], dtype='object')\n",
      "\n",
      "Showing .keys() property:\n",
      "Index(['population', 'city_country'], dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a Pandas df object named city_dataframe from a dict of series objects using population \n",
    "# and city_country\n",
    "city_dataframe = pd.DataFrame({'population': population,\n",
    "                               'city_country': city_country})\n",
    "print('DataFrame:\\n', city_dataframe, '\\n')\n",
    "# this was super cool ;) -> for end comments talk about this\n",
    "print(f'Showing .index property:\\n{city_dataframe.index}\\n')\n",
    "print(f'Showing .columns property:\\n{city_dataframe.columns}\\n')\n",
    "print(f'Showing .keys() property:\\n{city_dataframe.keys()}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbfb5e9",
   "metadata": {},
   "source": [
    "# Requirement 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2882f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series:\n",
      "\n",
      "Art                        96\n",
      "Music                      85\n",
      "C++                        90\n",
      "Java                       85\n",
      "Multivariable Calculus     78\n",
      "Mathematical Statistics    90\n",
      "Engineering 102            94\n",
      "Engineering 216            87\n",
      "Stats 211                  84\n",
      "Cooking Elective           85\n",
      "dtype: int64\n",
      "\n",
      "Modifying Art grade value based on a key:\n",
      "\n",
      "Art                        94\n",
      "Music                      85\n",
      "C++                        90\n",
      "Java                       85\n",
      "Multivariable Calculus     78\n",
      "Mathematical Statistics    90\n",
      "Engineering 102            94\n",
      "Engineering 216            87\n",
      "Stats 211                  84\n",
      "Cooking Elective           85\n",
      "dtype: int64\n",
      "\n",
      "Slicing by explicit index (C++ -> Stats 211)\n",
      "\n",
      "C++                        90\n",
      "Java                       85\n",
      "Multivariable Calculus     78\n",
      "Mathematical Statistics    90\n",
      "Engineering 102            94\n",
      "Engineering 216            87\n",
      "Stats 211                  84\n",
      "dtype: int64\n",
      "\n",
      "Slicing by implicit integer index (the last three):\n",
      "\n",
      "Engineering 216     87\n",
      "Stats 211           84\n",
      "Cooking Elective    85\n",
      "dtype: int64\n",
      "\n",
      "Demonstrating masking (filtering all grades higher than 85%):\n",
      "\n",
      "Art                        94\n",
      "C++                        90\n",
      "Mathematical Statistics    90\n",
      "Engineering 102            94\n",
      "Engineering 216            87\n",
      "dtype: int64\n",
      "\n",
      "Demonstration of fancy indexing (access grades for C++ and Java):\n",
      "\n",
      "C++     90\n",
      "Java    85\n",
      "dtype: int64\n",
      "\n",
      "Using .loc to access first three grades:\n",
      "\n",
      "Art      94\n",
      "Music    85\n",
      "C++      90\n",
      "dtype: int64\n",
      "Using .iloc to do the same thing:\n",
      "\n",
      "Art      94\n",
      "Music    85\n",
      "C++      90\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# create a pandas series object named my_pd_series from coll of string keys and collection of numeric values \n",
    "# of your choosing\n",
    "import numpy as np\n",
    "grades = np.random.randint(75, 100, size=10)\n",
    "ind = pd.Index(['Art', 'Music', 'C++', 'Java', 'Multivariable Calculus', 'Mathematical Statistics',\n",
    "               'Engineering 102', 'Engineering 216', 'Stats 211', 'Cooking Elective'])\n",
    "my_pd_series = pd.Series(grades, index=ind)\n",
    "\n",
    "print('Series:\\n\\n', my_pd_series, sep='')\n",
    "print('\\nModifying Art grade value based on a key:\\n')\n",
    "my_pd_series['Art'] = 94\n",
    "print(my_pd_series)\n",
    "print('\\nSlicing by explicit index (C++ -> Stats 211)\\n')\n",
    "print(my_pd_series['C++':'Stats 211'])\n",
    "print('\\nSlicing by implicit integer index (the last three):\\n')\n",
    "print(my_pd_series[-3:])\n",
    "print('\\nDemonstrating masking (filtering all grades higher than 85%):\\n')\n",
    "print(my_pd_series[my_pd_series > 85])\n",
    "print('\\nDemonstration of fancy indexing (access grades for C++ and Java):\\n')\n",
    "print(my_pd_series[['C++', 'Java']])\n",
    "print('\\nUsing .loc to access first three grades:\\n')\n",
    "print(my_pd_series.loc['Art': 'C++'])\n",
    "print('Using .iloc to do the same thing:\\n')\n",
    "print(my_pd_series.iloc[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d148a951",
   "metadata": {},
   "source": [
    "# Requirement 10: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "67f2698d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing the population column via dict style method:\n",
      "\n",
      "Chongquing     31020000.0\n",
      "Shanghai       27795702.0\n",
      "Tokyo          13960000.0\n",
      "Moscow         12593252.0\n",
      "Mexico City    21918936.0\n",
      "London          9425622.0\n",
      "New York       18823000.0\n",
      "Name: population, dtype: float64\n",
      "\n",
      "Doing the same thing but using the other method:\n",
      "\n",
      "Chongquing     31020000.0\n",
      "Shanghai       27795702.0\n",
      "Tokyo          13960000.0\n",
      "Moscow         12593252.0\n",
      "Mexico City    21918936.0\n",
      "London          9425622.0\n",
      "New York       18823000.0\n",
      "Name: population, dtype: float64\n",
      "\n",
      "Dataframe with altitude column added:\n",
      "\n",
      "             population   city_country  altitude\n",
      "Chongquing   31020000.0          China    801.00\n",
      "Shanghai     27795702.0          China     13.12\n",
      "Tokyo        13960000.0          Japan    131.00\n",
      "Moscow       12593252.0         Russia    157.00\n",
      "Mexico City  21918936.0         Mexico   7382.00\n",
      "London        9425622.0        England     36.00\n",
      "New York     18823000.0  United States     33.00\n"
     ]
    }
   ],
   "source": [
    "# using city_dataframe, demonstrate accessing column via dict style indexing of the column name\n",
    "# access column via the column names that are strings\n",
    "\n",
    "# dict style indexing of col name\n",
    "print('Accessing the population column via dict style method:\\n\\n', city_dataframe['population'], sep='')\n",
    "# access via column string\n",
    "print('\\nDoing the same thing but using the other method:\\n\\n', city_dataframe.population, sep='')\n",
    "\n",
    "# add a new column to the dataframe named altitude\n",
    "altitudes = [801, 13.12, 131, 157, 7382, 36, 33]\n",
    "city_dataframe['altitude'] = altitudes\n",
    "print(f'\\nDataframe with altitude column added:\\n\\n{city_dataframe}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1743b8b",
   "metadata": {},
   "source": [
    "# Requirement 11:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b8d255ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding two series and producing NaN vals:\n",
      "0     58.0\n",
      "1     72.0\n",
      "2     46.0\n",
      "3     61.0\n",
      "4     44.0\n",
      "5     29.0\n",
      "6     67.0\n",
      "7     50.0\n",
      "8     37.0\n",
      "9     48.0\n",
      "10     NaN\n",
      "11     NaN\n",
      "12     NaN\n",
      "13     NaN\n",
      "14     NaN\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Using .add() method and filling those NaN vals with the mean:\n",
      "0     58.0\n",
      "1     72.0\n",
      "2     46.0\n",
      "3     61.0\n",
      "4     44.0\n",
      "5     29.0\n",
      "6     67.0\n",
      "7     50.0\n",
      "8     37.0\n",
      "9     48.0\n",
      "10    52.2\n",
      "11    72.2\n",
      "12    70.2\n",
      "13    32.2\n",
      "14    56.2\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create two pandas series that when added using the + create some NaN vals and then use the .add()\n",
    "# and a fill value to replace the NaN entries\n",
    "uno = pd.Series(np.random.randint(0, 50, size=10))\n",
    "doce = pd.Series(np.random.randint(0, 50, size=15))\n",
    "print(f'Adding two series and producing NaN vals:\\n{uno+doce}')\n",
    "print(f'\\n\\nUsing .add() method and filling those NaN vals with the mean:\\n{uno.add(doce, fill_value=doce.mean())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1710c679",
   "metadata": {},
   "source": [
    "# Requirement 12:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "88925358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF #1:\n",
      "    A   B   C\n",
      "0   3  19  84\n",
      "1  10  22  59\n",
      "2  36   5  36\n",
      "\n",
      "DF #2:\n",
      "    D   C   B   A\n",
      "0   1  10  19  31\n",
      "1  25  25  20  27\n",
      "2  33  11  31  16\n",
      "3  14  17  29  21\n",
      "\n",
      "Adding and producing NaN values:\n",
      "      A     B     C   D\n",
      "0  34.0  38.0  94.0 NaN\n",
      "1  37.0  42.0  84.0 NaN\n",
      "2  52.0  36.0  47.0 NaN\n",
      "3   NaN   NaN   NaN NaN\n",
      "\n",
      "Adding and filling NaN values:\n",
      "        A       B       C       D\n",
      "0  34.000  38.000  94.000  21.625\n",
      "1  37.000  42.000  84.000  45.625\n",
      "2  52.000  36.000  47.000  53.625\n",
      "3  41.625  49.625  37.625  34.625\n"
     ]
    }
   ],
   "source": [
    "A = pd.DataFrame(np.random.randint(90, size=(3, 3)),\n",
    "                columns=list('ABC'))\n",
    "print('DF #1:\\n', A, sep='')\n",
    "B = pd.DataFrame(np.random.randint(34, size=(4, 4)),\n",
    "                columns=list('DCBA'))\n",
    "print('\\nDF #2:\\n', B, sep='')\n",
    "print(f'\\nAdding and producing NaN values:\\n{A+B}')\n",
    "print(f'\\nAdding and filling NaN values:\\n{A.add(B, fill_value=B.stack().mean())}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4e5a54",
   "metadata": {},
   "source": [
    "# Requirement 13:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4cd97879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array:\n",
      "[[8 9 7 9]\n",
      " [9 6 7 7]\n",
      " [7 9 8 7]\n",
      " [9 6 8 6]]\n",
      "Subtracting row zero from A:\n",
      "[[ 0  0  0  0]\n",
      " [ 1 -3  0 -2]\n",
      " [-1  0  1 -2]\n",
      " [ 1 -3  1 -3]]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "A = rng.randint(5, 10, size=(4, 4))\n",
    "print(f'Array:\\n{A}')\n",
    "print(f'Subtracting row zero from A:\\n{A-A[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e911355a",
   "metadata": {},
   "source": [
    "# Requirement 14:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "693a2ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame:\n",
      "   Q  R  S  T\n",
      "0  8  9  7  9\n",
      "1  9  6  7  7\n",
      "2  7  9  8  7\n",
      "3  9  6  8  6\n",
      "Subtracting row 1 of df using df.iloc[1]:\n",
      "   Q  R  S  T\n",
      "0 -1  3  0  2\n",
      "1  0  0  0  0\n",
      "2 -2  3  1  0\n",
      "3  0  0  1 -1\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(A, columns=list('QRST'))\n",
    "print(f'DataFrame:\\n{df}')\n",
    "print(f'Subtracting row 1 of df using df.iloc[1]:\\n{df-df.iloc[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcb7545",
   "metadata": {},
   "source": [
    "# Requirement 15:\n",
    "- None is one of the sentinel values used by Pandas and is a Python singleton object used for missing data in Python coede. None can only be used in arrays with dtype=object. There is typically more overhead and computations are slower with the operations done on the Python level so Pandas also uses NaN as a type for missing values. NaN stands for not a number and is a floating-point value recognized by all systems using IEEE floating-point representation. Arrays with NaN as the missing values can perform computations much faster as we will see in the next requirement. A big difference is that performing aggregations on an array with type None generally results in an error while those operations are well defined with NaN, although the results aren't necessarily meaningful if you do a computations and end up with a NaN value.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8f0011",
   "metadata": {},
   "source": [
    "# Requirement 16:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "97d3749a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timing sum() aggregation for type int:\n",
      "509 µs ± 8.77 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "\n",
      "Timing sum() aggregation for type object:\n",
      "26.4 ms ± 404 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "# dem %timeit diff using Python object and Python integers \n",
    "array = np.random.randint(0, 1e6, size=1000000)\n",
    "array2 = np.arange(1e6, dtype='object')\n",
    "print('Timing sum() aggregation for type int:')\n",
    "%timeit array.sum()\n",
    "print(f'\\nTiming sum() aggregation for type object:')\n",
    "%timeit array2.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c00df0",
   "metadata": {},
   "source": [
    "# Requirement 17: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0e708ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data is:\n",
      "0                    23\n",
      "1           Casey Quinn\n",
      "2                   NaN\n",
      "3                  None\n",
      "4                  98.7\n",
      "5    Los Angeles Lakers\n",
      "6       [1, 2, 3, 4, 5]\n",
      "7                  None\n",
      "dtype: object\n",
      "\n",
      "The null elements are:\n",
      "2     NaN\n",
      "3    None\n",
      "7    None\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = pd.Series([23, 'Casey Quinn', np.nan, None, 98.7, \n",
    "                  'Los Angeles Lakers', [1, 2, 3, 4, 5], None])\n",
    "print(f'The data is:\\n{data}')\n",
    "# filter out null vals\n",
    "filt = data.isnull()\n",
    "print('\\nThe null elements are:\\n', data[filt], sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8468fb1",
   "metadata": {},
   "source": [
    "# Requirement 18:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bd1b4697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas DataFrame:\n",
      "           Q     R     S      T\n",
      "0     np.nan  78.0  89.0     78\n",
      "1         90  89.0   NaN  Hello\n",
      "2 -1000000.0   NaN   NaN      8\n",
      "\n",
      "Dropping all rows containing a null value:\n",
      "        Q     R     S   T\n",
      "0  np.nan  78.0  89.0  78\n",
      "\n",
      "Dropping all columns containing a null value:\n",
      "           Q      T\n",
      "0     np.nan     78\n",
      "1         90  Hello\n",
      "2 -1000000.0      8\n",
      "\n",
      "Adding a nan column:\n",
      "           Q     R     S      T   4\n",
      "0     np.nan  78.0  89.0     78 NaN\n",
      "1         90  89.0   NaN  Hello NaN\n",
      "2 -1000000.0   NaN   NaN      8 NaN\n",
      "\n",
      "Removing column with all NaN vals:\n",
      "           Q     R     S      T\n",
      "0     np.nan  78.0  89.0     78\n",
      "1         90  89.0   NaN  Hello\n",
      "2 -1000000.0   NaN   NaN      8\n",
      "\n",
      "Adding NaN row on the bottem:\n",
      "           Q     R     S      T   4\n",
      "0     np.nan  78.0  89.0     78 NaN\n",
      "1         90  89.0   NaN  Hello NaN\n",
      "2 -1000000.0   NaN   NaN      8 NaN\n",
      "3        NaN   NaN   NaN    NaN NaN\n",
      "\n",
      "Dropping the rows with all NaN values:\n",
      "           Q     R     S      T   4\n",
      "0     np.nan  78.0  89.0     78 NaN\n",
      "1         90  89.0   NaN  Hello NaN\n",
      "2 -1000000.0   NaN   NaN      8 NaN\n",
      "\n",
      "Filling all NaN values with 0:\n",
      "           Q     R     S      T    4\n",
      "0     np.nan  78.0  89.0     78  0.0\n",
      "1         90  89.0   0.0  Hello  0.0\n",
      "2 -1000000.0   0.0   0.0      8  0.0\n",
      "3          0   0.0   0.0      0  0.0\n",
      "\n",
      "Forward filling all NaN values:\n",
      "           Q          R          S      T      4\n",
      "0     np.nan       78.0       89.0     78     78\n",
      "1         90       89.0       89.0  Hello  Hello\n",
      "2 -1000000.0 -1000000.0 -1000000.0    8.0    8.0\n",
      "3        NaN        NaN        NaN    NaN    NaN\n",
      "\n",
      "Back filling all NaN values:\n",
      "           Q     R      S      T    4\n",
      "0     np.nan  78.0   89.0     78  NaN\n",
      "1         90  89.0  Hello  Hello  NaN\n",
      "2 -1000000.0   8.0    8.0    8.0  NaN\n",
      "3        NaN   NaN    NaN    NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame([['np.nan', 78, 89, 78],\n",
    "                   [90, 89, np.nan, 'Hello'],\n",
    "                   [-1e6, np.nan, None, 8]], columns=list('QRST'))\n",
    "print(f'Pandas DataFrame:\\n{df}')\n",
    "print(f'\\nDropping all rows containing a null value:\\n{df.dropna()}')\n",
    "print(f'\\nDropping all columns containing a null value:\\n{df.dropna(axis=1)}\\n')\n",
    "df[4] = np.nan\n",
    "print('Adding a nan column:\\n', df, sep='')\n",
    "print(f\"\\nRemoving column with all NaN vals:\\n{df.dropna(how='all', axis='columns')}\")\n",
    "print('\\nAdding NaN row on the bottem:')\n",
    "df.loc[3] = np.nan\n",
    "print(df)\n",
    "print(f\"\\nDropping the rows with all NaN values:\\n{df.dropna(how='all', axis='rows')}\")\n",
    "print(f\"\\nFilling all NaN values with 0:\\n{df.fillna(0)}\")\n",
    "print(f\"\\nForward filling all NaN values:\\n{df.fillna(method='ffill', axis=1)}\")\n",
    "print(f\"\\nBack filling all NaN values:\\n{df.fillna(method='bfill', axis=1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed61bef2",
   "metadata": {},
   "source": [
    "# Requirement 19:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b79d176f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndexed:\n",
      "California  2000    33871648\n",
      "            2010    37253956\n",
      "New York    2000    18976457\n",
      "            2010    19378102\n",
      "Texas       2000    20851820\n",
      "            2010    25145561\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Unstacked:\n",
      "                2000      2010\n",
      "California  33871648  37253956\n",
      "New York    18976457  19378102\n",
      "Texas       20851820  25145561\n",
      "\n",
      "Stacked:\n",
      "California  2000    33871648\n",
      "            2010    37253956\n",
      "New York    2000    18976457\n",
      "            2010    19378102\n",
      "Texas       2000    20851820\n",
      "            2010    25145561\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "index = [('California', 2000), ('California', 2010),\n",
    "         ('New York', 2000), ('New York', 2010),\n",
    "         ('Texas', 2000), ('Texas', 2010)]\n",
    "populations = [33871648, 37253956,\n",
    "               18976457, 19378102,\n",
    "               20851820, 25145561]\n",
    "pop = pd.Series(populations, index=index)\n",
    "\n",
    "index = pd.MultiIndex.from_tuples(index)\n",
    "pop = pop.reindex(index)\n",
    "print('MultiIndexed:\\n', pop, sep='')\n",
    "pop_df = pop.unstack()\n",
    "print('\\n\\nUnstacked:\\n', pop_df, sep='')\n",
    "print('\\nStacked:\\n', pop_df.stack(), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ea5ab4",
   "metadata": {},
   "source": [
    "# Requirement 20: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e18af06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1             Aprilia\n",
       "2                 BMW\n",
       "3              Ducati\n",
       "4     Harley Davidson\n",
       "5              Indian\n",
       "6                 KTM\n",
       "7              Suzuki\n",
       "8               Acura\n",
       "9             Bentley\n",
       "10              Buick\n",
       "11           Cadillac\n",
       "12          Chevrolet\n",
       "13           Cadillac\n",
       "14            Bentley\n",
       "15               Audi\n",
       "dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motorcycle_brands = pd.Series(['Aprilia', 'BMW', 'Ducati',\n",
    "                               'Harley Davidson', 'Indian', 'KTM','Suzuki'], \n",
    "                              index=[1, 2, 3, 4, 5, 6, 7])\n",
    "car_brands = pd.Series(['Acura', 'Bentley', 'Buick', 'Cadillac',\n",
    "                        'Chevrolet', 'Cadillac', 'Bentley', 'Audi'],\n",
    "                       index=[8, 9, 10, 11, 12, 13, 14, 15])\n",
    "pd.concat([motorcycle_brands, car_brands])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c70e639",
   "metadata": {},
   "source": [
    "# Requirement 21:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "04d06cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aprilia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BMW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ducati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harley Davidson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Indian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KTM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Suzuki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Acura</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Bentley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Buick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Cadillac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chevrolet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cadillac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bentley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Audi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "1           Aprilia\n",
       "2               BMW\n",
       "3            Ducati\n",
       "4   Harley Davidson\n",
       "5            Indian\n",
       "6               KTM\n",
       "7            Suzuki\n",
       "8             Acura\n",
       "9           Bentley\n",
       "10            Buick\n",
       "11         Cadillac\n",
       "12        Chevrolet\n",
       "13         Cadillac\n",
       "14          Bentley\n",
       "15             Audi"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motorcycle_brands = pd.DataFrame(motorcycle_brands)\n",
    "car_brands = pd.DataFrame(car_brands)\n",
    "motorcycle_brands.append(car_brands)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fbde5d",
   "metadata": {},
   "source": [
    "# Requirement 22:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "00bacb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df1\n",
      "             Name        Position\n",
      "0  Allen Iverson     Point Guard\n",
      "1    Kobe Bryant  Shooting Guard\n",
      "2     Jason Kidd     Point Guard\n",
      "3     Chris Paul     Point Guard\n",
      "df2\n",
      "             Name   Team:\n",
      "0  Allen Iverson   76ers\n",
      "1    Kobe Bryant  Lakers\n",
      "2     Jason Kidd    Nets\n",
      "3     Chris Paul    Suns\n",
      "df1 and df2 merged:\n",
      "            Name        Position   Team:\n",
      "0  Allen Iverson     Point Guard   76ers\n",
      "1    Kobe Bryant  Shooting Guard  Lakers\n",
      "2     Jason Kidd     Point Guard    Nets\n",
      "3     Chris Paul     Point Guard    Suns\n",
      "Many to one:\n",
      "            Name        Position   Team:       Trainer\n",
      "0  Allen Iverson     Point Guard   76ers   Casey Quinn\n",
      "1     Jason Kidd     Point Guard    Nets   Casey Quinn\n",
      "2     Chris Paul     Point Guard    Suns   Casey Quinn\n",
      "3    Kobe Bryant  Shooting Guard  Lakers  Connor Quinn\n",
      "Many-to-Many:\n",
      "             Name        Position        Skills\n",
      "0   Allen Iverson     Point Guard     Crossover\n",
      "1   Allen Iverson     Point Guard       Passing\n",
      "2   Allen Iverson     Point Guard       Defense\n",
      "3      Jason Kidd     Point Guard     Crossover\n",
      "4      Jason Kidd     Point Guard       Passing\n",
      "5      Jason Kidd     Point Guard       Defense\n",
      "6      Chris Paul     Point Guard     Crossover\n",
      "7      Chris Paul     Point Guard       Passing\n",
      "8      Chris Paul     Point Guard       Defense\n",
      "9     Kobe Bryant  Shooting Guard       Dunking\n",
      "10    Kobe Bryant  Shooting Guard  Intimidation\n"
     ]
    }
   ],
   "source": [
    "# one to one join \n",
    "df1 = pd.DataFrame({'Name': ['Allen Iverson', 'Kobe Bryant', 'Jason Kidd', 'Chris Paul'],\n",
    "                   'Position': ['Point Guard', 'Shooting Guard', 'Point Guard', 'Point Guard']})\n",
    "#                     'Team:': ['76ers', 'Lakers', 'Nets', 'Suns']})\n",
    "                    \n",
    "df2 = pd.DataFrame({'Name': ['Allen Iverson', 'Kobe Bryant', 'Jason Kidd', 'Chris Paul'],\n",
    "                             'Team:': ['76ers', 'Lakers', 'Nets', 'Suns']})\n",
    "\n",
    "#                     'Position': ['Point Guard', 'Shooting Guard', 'Point Guard', 'Point Guard']})\n",
    "\n",
    "print('df1\\n', df1)\n",
    "print('df2\\n', df2)\n",
    "df3 = pd.merge(df1, df2)\n",
    "print(f'df1 and df2 merged:\\n{df3}')\n",
    "df4 = pd.DataFrame({'Position': ['Point Guard', 'Shooting Guard', 'Small Forward'],\n",
    "                    'Trainer': ['Casey Quinn', 'Connor Quinn', 'Sean Quinn']})\n",
    "print('Many to one:\\n', pd.merge(df3, df4), sep ='')\n",
    "df5 = pd.DataFrame({'Position': ['Point Guard', 'Point Guard', 'Point Guard', 'Shooting Guard', 'Shooting Guard'],\n",
    "                   'Skills': ['Crossover', 'Passing', 'Defense', 'Dunking', 'Intimidation']})\n",
    "print('Many-to-Many:\\n', pd.merge(df1, df5), sep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f206fc",
   "metadata": {},
   "source": [
    "# Requirement 23:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0a975ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demonstrating merge with on keyword:\n",
      "            Name        Position   Team:\n",
      "0  Allen Iverson     Point Guard   76ers\n",
      "1    Kobe Bryant  Shooting Guard  Lakers\n",
      "2     Jason Kidd     Point Guard    Nets\n",
      "3     Chris Paul     Point Guard    Suns\n"
     ]
    }
   ],
   "source": [
    "print('Demonstrating merge with on keyword:\\n', pd.merge(df1, df2, on='Name'), sep='')\n",
    "df3 = pd.DataFrame({'Name': ['Allen Iverson', 'Kobe Bryant', 'Jason Kidd', 'Chris Paul'],\n",
    "                             'Salary:': ['7.7 million', '21.5 million', '4.9 million', '23.7 million']})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f898cbbe",
   "metadata": {},
   "source": [
    "# Requirement 24:\n",
    "This assignment was a lot of fun for me. I wish I had given myself one more day to work on it because I was really getting to new concepts in Pandas that like you said require a lot of time to think about. I am excited that I am off work tomorrow to study Pandas more and get going on the next weeks material. It would be helpful ot have some video content but I am sure I can find some on YouTube. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
